%University of Dayton
%Inceptive Event Time Surfaces - ICIAR 2019
%29AUG2019

%Transfer Learning

%Run from 'code' directory

clear, clc

% mainPath = ['..' filesep 'time_surfaces' filesep];
mainPath = '/home/wescomp/data/MNIST/'

checkpointPath = [mainPath 'network_checkpoints' filesep];

if ~exist(checkpointPath, 'dir')
    mkdir(checkpointPath)
end

%load pretrained network
% net = googlenet;

testImageStore = imageDatastore([mainPath 'features' filesep 'test'],...
    'IncludeSubfolders',true,'FileExtensions','.nii','LabelSource','foldernames','ReadFcn',@(x) readNifti_ncars(x,1:6,false));

trainImageStore = imageDatastore([mainPath 'features' filesep 'train'],...
    'IncludeSubfolders',true,'FileExtensions','.nii','LabelSource','foldernames','ReadFcn',@(x) readNifti_ncars(x,1:6,false));
numTrain = numel(trainImageStore.Files);

% %Augment training data by flipping left/right
% imageAugmenter = imageDataAugmenter( ...
%     'RandXReflection', true);
% 
% atrainImageStore = augmentedImageDatastore([224 224],trainImageStore,'DataAugmentation',imageAugmenter);

% makePretrainedNetworkGoogleNet %~97.84 max (2x googlenets)
% makePretrainedNetworkMobileNetv2 %~96.68 max
% makePretrainedNetworkGoogleNet_3d_v2 %~97.47 max
% makePretrainedNetworkGoogleNet_3d_additionalFClayer %~97.77max
makePretrainedNetworkGoogleNet_3d_nmnist
%simple CNN trained on features = ~85%acc

%CNN
miniBatchSize  = 2^6;
validationFrequency = floor(numTrain/miniBatchSize);
% options = trainingOptions('adam', ...
%     'MiniBatchSize',miniBatchSize, ...
%     'MaxEpochs',50, ...
%     'InitialLearnRate',1e-4, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropFactor',0.1, ...
%     'LearnRateDropPeriod',45, ...
%     'ValidationData',testImageStore, ...
%     'ValidationFrequency',validationFrequency, ...
%     'Shuffle','every-epoch', ...
%     'Plots','training-progress', ...
%     'ResetInputNormalization', false, ...
%     'CheckpointPath',checkpointPath,...
%     'DispatchInBackground',true,...
%     'Verbose',true);
options = trainingOptions('adam', ...
    'MiniBatchSize',miniBatchSize, ...
    'MaxEpochs',24, ...
    'InitialLearnRate',1e-4, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropFactor',0.5, ...
    'LearnRateDropPeriod',6, ...
    'ValidationData',testImageStore, ...
    'ValidationFrequency',validationFrequency, ...
    'Shuffle','every-epoch', ...
    'Plots','training-progress', ...
    'ResetInputNormalization', false, ...
    'CheckpointPath',checkpointPath,...
    'DispatchInBackground',true,...
    'Verbose',true);
%         'ValidationData',{XTest,YTest'}, ...
% 'ValidationPatience',5, ...
%     'DispatchInBackground', true, ...

% %         net = trainNetwork(XTrain,categorical(YTrain),layers,options);
% %         net = trainNetwork(auimds,layers,options);
[net,info] = trainNetwork(trainImageStore, lgraph, options); %~97.84 max
% [net,info] = trainNetwork(trainImageStore, layerGraph(net), options); %retrain with augmentation %97.77 max with aug

[YPred,probs] = classify(net,testImageStore);
accuracy = mean(YPred == testImageStore.Labels)

save('trainedNetworks/googlenet_3d_nmnist_noaugmentation_9940acc_v1.mat','net')

%%
%SVM
% classifier = fitcecoc(featuresTrain,YTrain); %~77acc
classifier = fitcecoc(featuresTrain1,trainImageStoreP1.Labels); %~76acc
YPred = predict(classifier,featuresTest);
accuracy = mean(YPred == YTest)
plotconfusion(YTest,YPred)

% acc_9755 training options (nvidia 800m)
% options = trainingOptions('adam', ...
%     'MiniBatchSize',10, ...
%     'MaxEpochs',24, ...
%     'InitialLearnRate',1e-4, ...
%     'Shuffle','every-epoch', ...
%     'ValidationData',avalImageStore, ...
%     'ValidationFrequency',1542, ...
%     'LearnRateSchedule','piecewise',...
%     'LearnRateDropPeriod',6,...
%     'LearnRateDropFactor',.5,...
%     'Verbose',true, ...
%     'CheckpointPath',checkpointPath, ...
%     'Plots','training-progress');

% training options (nvidia 2080 Ti)
options = trainingOptions('adam', ...
    'MiniBatchSize',500, ...
    'MaxEpochs',24, ...
    'InitialLearnRate',1e-4, ...
    'Shuffle','every-epoch', ...
    'ValidationData',avalImageStore, ...
    'ValidationFrequency',30, ...
    'LearnRateSchedule','piecewise',...
    'LearnRateDropPeriod',6,...
    'LearnRateDropFactor',.5,...
    'Verbose',true, ...
    'CheckpointPath',checkpointPath, ...
    'Plots','training-progress');

net = trainNetwork(atrainImageStore,lgraph,options);

% [net,info] = trainNetwork(dsTrain, layerGraph(net), options); %retrain


if false
    %Load a network with transfer learning complete
    load('iets_trained_net.mat')
end

[YPred,probs] = classify(net,testImageStore);
accuracy = mean(YPred == testImageStore.Labels)
auc = scoreAUC(testImageStore.Labels=='cars',probs(:,2))
