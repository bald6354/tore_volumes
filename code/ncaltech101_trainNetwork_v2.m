%University of Dayton
%Inceptive Event Time Surfaces - ICIAR 2019
%29AUG2019

%Transfer Learning

%Run from 'code' directory

clear, clc

% mainPath = ['..' filesep 'time_surfaces' filesep];
mainPath = '/home/wescomp/data/N-Caltech101/'

checkpointPath = [mainPath 'network_checkpoints' filesep];

if ~exist(checkpointPath, 'dir')
    mkdir(checkpointPath)
end

%load pretrained network
% net = googlenet;

imageStore = imageDatastore([mainPath 'features_v2' filesep],...
    'IncludeSubfolders',true,'FileExtensions','.nii','LabelSource','foldernames','ReadFcn',@(x) readNifti_ncaltech101(x,1:12,false,0));

% [testImageStore,trainImageStore] = splitEachLabel(imageStore,15); %orig paper used 15 test samples per class
[testImageStore,trainImageStore] = splitEachLabel(imageStore,0.33,'randomized'); %e2vid paper used 66/33 split

numTest = numel(testImageStore.Files)
numTrain = numel(trainImageStore.Files)

%% Due to large class imbalance we use oversampling to help balance
% % % 
% % % labels=trainImageStore.Labels;
% % % [G,classes] = findgroups(labels);
% % % numObservations = splitapply(@numel,labels,G);
% % % desiredNumObservationsPerClass = max(numObservations);
% % % files = splitapply(@(x){randReplicateFiles(x,desiredNumObservationsPerClass)},trainImageStore.Files,G);
% % % files = vertcat(files{:});
% % % labels=[];
% % % info=strfind(files,filesep);
% % % for i=1:numel(files)
% % %     idx=info{i};
% % %     dirName=files{i};
% % %     targetStr=dirName(idx(end-1)+1:idx(end)-1);
% % %     targetStr2=cellstr(targetStr);
% % %     labels=[labels;categorical(targetStr2)];
% % % end
% % % trainImageStore.Files = files;
% % % trainImageStore.Labels=labels;
% % % labelCount_oversampled = countEachLabel(trainImageStore)
% % % histogram(trainImageStore.Labels)
% % % numTrain = numel(trainImageStore.Files)
% % % 

% %add random l/r flip to oversampled training data (best so far)
% trainImageStore.ReadFcn = @(x) readNifti_ncars(x,1:6,true)
%add random l/r flip and shifts to oversampled training data 
trainImageStore.ReadFcn = @(x) readNifti_ncaltech101(x,1:12,true,15)

% %Augment training data by flipping left/right
% imageAugmenter = imageDataAugmenter( ...
%     'RandXReflection', true);
% 
% atrainImageStore = augmentedImageDatastore([224 224],trainImageStore,'DataAugmentation',imageAugmenter);

% makePretrainedNetworkGoogleNet_3d_ncaltech101 %~79.87 orig paper method (82.78 e2vid split)
% makePretrainedNetworkGoogleNet_3d_ncaltech101_v2 %~83.37 (best so far)
makePretrainedNetworkGoogleNet_3d_ncaltech101_v3 %~???
%simple CNN trained on features = ~85%acc

%CNN
miniBatchSize  = 2^6;
validationFrequency = floor(numTrain/miniBatchSize);
options = trainingOptions('adam', ...
    'MiniBatchSize',miniBatchSize, ...
    'MaxEpochs',75, ...
    'InitialLearnRate',1e-4, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropFactor',0.1, ...
    'LearnRateDropPeriod',60, ...
    'ValidationData',testImageStore, ...
    'ValidationFrequency',validationFrequency, ...
    'Shuffle','every-epoch', ...
    'Plots','training-progress', ...
    'ResetInputNormalization', false, ...
    'CheckpointPath',checkpointPath,...
    'DispatchInBackground',true,...
    'Verbose',true);
if false
options = trainingOptions('adam', ...
    'MiniBatchSize',miniBatchSize, ...
    'MaxEpochs',24, ...
    'InitialLearnRate',1e-4, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropFactor',0.5, ...
    'LearnRateDropPeriod',6, ...
    'ValidationData',testImageStore, ...
    'ValidationFrequency',validationFrequency, ...
    'Shuffle','every-epoch', ...
    'Plots','training-progress', ...
    'ResetInputNormalization', false, ...
    'CheckpointPath',checkpointPath,...
    'DispatchInBackground',true,...
    'Verbose',true);
end
%         'ValidationData',{XTest,YTest'}, ...
% 'ValidationPatience',5, ...
%     'DispatchInBackground', true, ...

% %         net = trainNetwork(XTrain,categorical(YTrain),layers,options);
% %         net = trainNetwork(auimds,layers,options);
[net,info] = trainNetwork(trainImageStore, lgraph, options);
% [net,info] = trainNetwork(trainImageStore, layerGraph(net), options); %retrain

[YPred,probs] = classify(net,testImageStore);
accuracy = mean(YPred == testImageStore.Labels)

save('trainedNetworks/googlenet_3d_ncaltech101_augmentation_7987acc_v1.mat','net')

%%
%SVM
% classifier = fitcecoc(featuresTrain,YTrain); %~77acc
classifier = fitcecoc(featuresTrain1,trainImageStoreP1.Labels); %~76acc
YPred = predict(classifier,featuresTest);
accuracy = mean(YPred == YTest)
plotconfusion(YTest,YPred)

% acc_9755 training options (nvidia 800m)
% options = trainingOptions('adam', ...
%     'MiniBatchSize',10, ...
%     'MaxEpochs',24, ...
%     'InitialLearnRate',1e-4, ...
%     'Shuffle','every-epoch', ...
%     'ValidationData',avalImageStore, ...
%     'ValidationFrequency',1542, ...
%     'LearnRateSchedule','piecewise',...
%     'LearnRateDropPeriod',6,...
%     'LearnRateDropFactor',.5,...
%     'Verbose',true, ...
%     'CheckpointPath',checkpointPath, ...
%     'Plots','training-progress');

% training options (nvidia 2080 Ti)
options = trainingOptions('adam', ...
    'MiniBatchSize',500, ...
    'MaxEpochs',24, ...
    'InitialLearnRate',1e-4, ...
    'Shuffle','every-epoch', ...
    'ValidationData',avalImageStore, ...
    'ValidationFrequency',30, ...
    'LearnRateSchedule','piecewise',...
    'LearnRateDropPeriod',6,...
    'LearnRateDropFactor',.5,...
    'Verbose',true, ...
    'CheckpointPath',checkpointPath, ...
    'Plots','training-progress');

net = trainNetwork(atrainImageStore,lgraph,options);

% [net,info] = trainNetwork(dsTrain, layerGraph(net), options); %retrain


if false
    %Load a network with transfer learning complete
    load('iets_trained_net.mat')
end

[YPred,probs] = classify(net,testImageStore);
accuracy = mean(YPred == testImageStore.Labels)
auc = scoreAUC(testImageStore.Labels=='cars',probs(:,2))
